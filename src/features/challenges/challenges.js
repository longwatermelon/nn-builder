function createLinearSolution(weights, bias = 0, outputActivation = "linear") {
  return [
    { type: "input", activation: "linear", neuronCount: 2 },
    {
      type: "output",
      activation: outputActivation,
      neurons: [{ bias, weights: [...weights] }],
    },
  ];
}

function createSingleHiddenSolution({
  hiddenActivation = "relu",
  hiddenNeurons,
  outputWeights,
  outputBias = 0,
  outputActivation = "linear",
}) {
  return [
    { type: "input", activation: "linear", neuronCount: 2 },
    {
      type: "hidden",
      activation: hiddenActivation,
      neurons: hiddenNeurons.map((n) => ({ bias: n.bias, weights: [...n.weights] })),
    },
    {
      type: "output",
      activation: outputActivation,
      neurons: [{ bias: outputBias, weights: [...outputWeights] }],
    },
  ];
}

export const CHALLENGE_DEFS = [
  {
    id: "identity",
    name: "Identity",
    formula: "f(x_1, x_2) = x_1",
    difficulty: "tutorial",
    targetFn: (x1) => x1,
    solutionFactory: () => createLinearSolution([1, 0], 0, "linear"),
  },
  {
    id: "input_sum",
    name: "Input Sum",
    formula: "f(x_1, x_2) = x_1 + x_2",
    difficulty: "tutorial",
    targetFn: (x1, x2) => x1 + x2,
    solutionFactory: () => createLinearSolution([1, 1], 0, "linear"),
  },
  {
    id: "relu_ramp",
    name: "ReLU Ramp",
    formula: "f(x_1, x_2) = \\max(0, x_1)",
    difficulty: "tutorial",
    targetFn: (x1) => Math.max(0, x1),
    solutionFactory: () => createLinearSolution([1, 0], 0, "relu"),
  },
  {
    id: "tanh_curve",
    name: "Tanh Curve",
    formula: "f(x_1, x_2) = \\tanh(x_1)",
    difficulty: "tutorial",
    targetFn: (x1) => Math.tanh(x1),
    solutionFactory: () => createLinearSolution([1, 0], 0, "tanh"),
  },
  {
    id: "linear_combo",
    name: "Linear Combo",
    formula: "f(x_1, x_2) = 2x_1 - x_2 + 1",
    difficulty: "easy",
    targetFn: (x1, x2) => 2 * x1 - x2 + 1,
    solutionFactory: () => createLinearSolution([2, -1], 1, "linear"),
  },
  {
    id: "step_edge",
    name: "Step Edge",
    formula: "f(x_1, x_2) = \\begin{cases}1,&x_1 \\ge 0\\\\-1,&x_1 < 0\\end{cases}",
    difficulty: "easy",
    targetFn: (x1) => (x1 >= 0 ? 1 : -1),
    solutionFactory: () => createLinearSolution([2.8, 0], 0, "tanh"),
  },
  {
    id: "absolute_value",
    name: "Absolute Value",
    formula: "f(x_1, x_2) = \\left|x_1\\right|",
    difficulty: "medium",
    targetFn: (x1) => Math.abs(x1),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 0, weights: [1, 0] },
          { bias: 0, weights: [-1, 0] },
        ],
        outputWeights: [1, 1],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "max_two_inputs",
    name: "Max Of Two",
    formula: "f(x_1, x_2) = \\max(x_1, x_2)",
    difficulty: "medium",
    targetFn: (x1, x2) => Math.max(x1, x2),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 0, weights: [1, -1] },
          { bias: 0, weights: [0, 1] },
          { bias: 0, weights: [0, -1] },
        ],
        outputWeights: [1, 1, -1],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "absolute_difference",
    name: "Absolute Difference",
    formula: "f(x_1, x_2) = \\left|x_1 - x_2\\right|",
    difficulty: "medium",
    targetFn: (x1, x2) => Math.abs(x1 - x2),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 0, weights: [1, -1] },
          { bias: 0, weights: [-1, 1] },
        ],
        outputWeights: [1, 1],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "roofline_lite",
    name: "Roofline Lite",
    formula: "f(x_1, x_2) = 0.25x_2 + \\max(0, x_1 + 1) - 1.2\\max(0, x_1 - 0.5)",
    difficulty: "hard",
    targetFn: (x1, x2) => 0.25 * x2 + Math.max(0, x1 + 1) - 1.2 * Math.max(0, x1 - 0.5),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 0, weights: [0, 1] },
          { bias: 0, weights: [0, -1] },
          { bias: 1, weights: [1, 0] },
          { bias: -0.5, weights: [1, 0] },
        ],
        outputWeights: [0.25, -0.25, 1, -1.2],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "tilted_notch_lite",
    name: "Tilted Notch Lite",
    formula: "f(x_1, x_2) = \\max(0, x_1 + 0.5x_2 + 1) - \\max(0, x_1 + 0.5x_2 - 1) - 0.35\\max(0, x_1 - x_2 - 1.2)",
    difficulty: "hard",
    targetFn: (x1, x2) =>
      Math.max(0, x1 + 0.5 * x2 + 1) - Math.max(0, x1 + 0.5 * x2 - 1) - 0.35 * Math.max(0, x1 - x2 - 1.2),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 1, weights: [1, 0.5] },
          { bias: -1, weights: [1, 0.5] },
          { bias: -1.2, weights: [1, -1] },
        ],
        outputWeights: [1, -1, -0.35],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "diamond_cap_lite",
    name: "Diamond Cap Lite",
    formula: "f(x_1, x_2) = \\max(0, 2 - \\left|x_1 - 1\\right| - 0.6\\left|x_2 + 0.8\\right|)",
    difficulty: "hard",
    targetFn: (x1, x2) => Math.max(0, 2 - Math.abs(x1 - 1) - 0.6 * Math.abs(x2 + 0.8)),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: -1, weights: [1, 0] },
          { bias: 1, weights: [-1, 0] },
          { bias: 0.8, weights: [0, 1] },
          { bias: -0.8, weights: [0, -1] },
        ],
        outputWeights: [-1, -1, -0.6, -0.6],
        outputBias: 2,
        outputActivation: "relu",
      }),
  },
  {
    id: "kinked_valley",
    name: "Kinked Valley",
    formula: "f(x_1, x_2) = \\left|x_1 - 1\\right| + 0.7\\left|x_2 + 1.5\\right| - 0.8\\max(0, x_1 + x_2 - 1)",
    difficulty: "insane",
    targetFn: (x1, x2) => Math.abs(x1 - 1) + 0.7 * Math.abs(x2 + 1.5) - 0.8 * Math.max(0, x1 + x2 - 1),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: -1, weights: [1, 0] },
          { bias: 1, weights: [-1, 0] },
          { bias: 1.5, weights: [0, 1] },
          { bias: -1.5, weights: [0, -1] },
          { bias: -1, weights: [1, 1] },
        ],
        outputWeights: [1, 1, 0.7, 0.7, -0.8],
        outputBias: 0,
        outputActivation: "linear",
      }),
  },
  {
    id: "offcenter_diamond_cap",
    name: "Offcenter Diamond Cap",
    formula: "f(x_1, x_2) = \\max(0, 2.2 - \\left|x_1 - 1.2\\right| - 0.6\\left|x_2 + 0.8\\right|)",
    difficulty: "insane",
    targetFn: (x1, x2) => Math.max(0, 2.2 - Math.abs(x1 - 1.2) - 0.6 * Math.abs(x2 + 0.8)),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: -1.2, weights: [1, 0] },
          { bias: 1.2, weights: [-1, 0] },
          { bias: 0.8, weights: [0, 1] },
          { bias: -0.8, weights: [0, -1] },
        ],
        outputWeights: [-1, -1, -0.6, -0.6],
        outputBias: 2.2,
        outputActivation: "relu",
      }),
  },
  {
    id: "three_axis_fold",
    name: "Three Axis Fold",
    formula:
      "f(x_1, x_2) = 0.2x_1 + \\max(0, x_1 + x_2 - 1) - 0.9\\max(0, x_1 - 1.5x_2 - 0.5) + 0.7\\max(0, -x_1 + 0.4x_2 + 1.5)",
    difficulty: "insane",
    hint: "3 hinges: one x₁ + x₂ diagonal and two opposing diagonals.",
    targetFn: (x1, x2) =>
      0.2 * x1 + Math.max(0, x1 + x2 - 1) - 0.9 * Math.max(0, x1 - 1.5 * x2 - 0.5) + 0.7 * Math.max(0, -x1 + 0.4 * x2 + 1.5),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "relu",
        hiddenNeurons: [
          { bias: 6, weights: [1, 0] },
          { bias: -1, weights: [1, 1] },
          { bias: -0.5, weights: [1, -1.5] },
          { bias: 1.5, weights: [-1, 0.4] },
        ],
        outputWeights: [0.2, 1, -0.9, 0.7],
        outputBias: -1.2,
        outputActivation: "linear",
      }),
  },
  {
    id: "input_product",
    name: "Input Product",
    formula: "f(x_1, x_2) = x_1 \\cdot x_2",
    difficulty: "exploratory",
    targetFn: (x1, x2) => x1 * x2,
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "tanh",
        hiddenNeurons: [
          { bias: -2.904888, weights: [-0.314079, -0.295811] },
          { bias: 2.381941, weights: [0.254961, -0.253669] },
          { bias: 1.890172, weights: [0.326464, -0.328184] },
          { bias: 3.515096, weights: [0.357379, 0.370763] },
          { bias: 2.01778, weights: [-0.296612, -0.293733] },
          { bias: 2.928578, weights: [-0.299237, 0.317606] },
          { bias: 2.557093, weights: [0.273685, -0.262489] },
          { bias: 3.033708, weights: [0.314292, 0.319684] },
          { bias: -1.148406, weights: [0.294619, 0.294989] },
          { bias: 3.120427, weights: [0.32011, -0.314567] },
          { bias: 2.108572, weights: [0.2316, -0.237778] },
          { bias: -2.318838, weights: [-0.248813, 0.250302] },
          { bias: -3.107367, weights: [0.330991, 0.311662] },
          { bias: 2.408475, weights: [-0.275003, 0.262526] },
          { bias: 2.822153, weights: [-0.274546, -0.314587] },
          { bias: 1.036625, weights: [-0.300875, 0.302046] },
          { bias: -3.30679, weights: [-0.326104, 0.34388] },
          { bias: 1.039322, weights: [0.303444, -0.303764] },
          { bias: 2.135306, weights: [0.313359, 0.315551] },
          { bias: 3.845866, weights: [-0.403084, 0.38476] },
          { bias: -2.821476, weights: [0.293265, -0.305792] },
          { bias: 3.125648, weights: [-0.332829, -0.31334] },
          { bias: 1.149576, weights: [0.292417, 0.293063] },
          { bias: -2.03977, weights: [0.337836, -0.336227] },
        ],
        outputWeights: [
          3.634216,
          2.308945,
          2.343795,
          -3.704366,
          -3.719146,
          2.9709,
          2.305849,
          -3.531657,
          3.687381,
          2.852449,
          2.42927,
          -2.508158,
          3.802508,
          2.980856,
          -3.812572,
          3.01127,
          -2.599527,
          2.59633,
          -3.573043,
          3.626878,
          -2.959818,
          -3.75151,
          -3.932598,
          -3.149955,
        ],
        outputBias: -1.456801,
        outputActivation: "linear",
      }),
  },
  {
    id: "sine_wave",
    name: "Sine Wave",
    formula: "f(x_1, x_2) = \\sin(x_1)",
    difficulty: "exploratory",
    targetFn: (x1) => Math.sin(x1),
    solutionFactory: () =>
      createSingleHiddenSolution({
        hiddenActivation: "tanh",
        hiddenNeurons: [
          { bias: 0.237772, weights: [0.55563, -0.000168] },
          { bias: 0.402373, weights: [0.482088, -0.001171] },
          { bias: 0.094491, weights: [0.502461, -0.006282] },
          { bias: 0.496975, weights: [0.477786, -0.001813] },
          { bias: -0.13228, weights: [-0.186954, -0.00069] },
          { bias: 1.976553, weights: [-0.899293, -0.000095] },
          { bias: 2.881629, weights: [0.857624, 0.000543] },
          { bias: -0.513163, weights: [-0.473029, -0.00557] },
          { bias: -1.47704, weights: [-0.695062, 0.00003] },
          { bias: 0.601725, weights: [0.48149, -0.002664] },
          { bias: 3.227008, weights: [-0.944779, 0.00035] },
          { bias: -0.18877, weights: [-0.50841, -0.001528] },
        ],
        outputWeights: [
          3.095853,
          -0.719523,
          -0.111042,
          -0.534438,
          -3.259329,
          0.868952,
          -1.212044,
          0.291017,
          0.863039,
          -0.44723,
          1.142495,
          0.44544,
        ],
        outputBias: -0.149593,
        outputActivation: "linear",
      }),
  },
];
